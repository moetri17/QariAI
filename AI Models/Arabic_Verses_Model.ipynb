{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data acquisition & curation for the Arabic **verses** dataset  \n",
        "\n",
        "This block automates the download, conversion, quality filtering, and splitting of Quranic verse audio files to build a high-quality dataset for verse-level recognition.  \n",
        "\n",
        "- **Target surahs:** Uses a controlled subset for manageability: Al-Fatiha (001, 7 ayahs), Al-Ikhlas (112, 4), Al-Falaq (113, 5), and An-Nas (114, 6).  \n",
        "- **Source & reciters:** Pulls recitations from *EveryAyah.com*, iterating through a large candidate list of reciters.  \n",
        "  - **Skip list:** Removes non-audio directories (e.g., `English`, `QuranText`, `MultiLanguage`).  \n",
        "  - **Alias resolution:** Handles inconsistent folder names with `_` vs. spaces and known aliases.  \n",
        "- **Download rules:**  \n",
        "  - For each reciter Ã— surah Ã— ayah, attempt multiple aliases until the file is found.  \n",
        "  - Retain a reciterâ€™s set if â‰¥80% of ayahs are successfully downloaded.  \n",
        "- **Audio normalisation:** Converts `.mp3` to `.wav` at **mono, 16 kHz, 16-bit PCM** using `ffmpeg`. Ensures consistency across reciters.  \n",
        "\n",
        "---\n",
        "\n",
        "# 2. Indexing & quality filtering  \n",
        "\n",
        "- **Index build:** Parses filenames into structured metadata: `reciter`, `surah`, `ayah`, `ayah_id`, and full `wav_path`.  \n",
        "- **Coverage checks:**  \n",
        "  - Builds per-reciter pivot tables of surah coverage.  \n",
        "  - Flags missing ayahs and computes % completion.  \n",
        "- **Bitrate parsing:** Extracts kbps tags (e.g., 64 kbps, 128 kbps) from reciter names to assess recording quality.  \n",
        "- **Good reciters criteria:**  \n",
        "  - 100% coverage for selected surahs.  \n",
        "  - Bitrate â‰¥64 kbps.  \n",
        "- **Curated dataset:** Filters index to only include *good reciters* with complete and clear recordings.  \n",
        "\n",
        "---\n",
        "\n",
        "# 3. Dataset split for model training  \n",
        "\n",
        "- **CSV export:** Writes curated index to `verses_index.csv`.  \n",
        "- **Splitting:** Stratifies by `ayah_id` to preserve class balance.  \n",
        "  - **Train:** 70%  \n",
        "  - **Validation:** 15%  \n",
        "  - **Test:** 15%  \n",
        "- **Diagnostics:** Prints number of rows, unique ayahs per split, and reciter distribution in each subset.  \n",
        "\n",
        "---\n",
        "\n",
        "**Key parameters:** Surahs `{001, 112, 113, 114}`, min coverage `80%` per reciter, final filter = *full coverage + â‰¥64 kbps bitrate*, splits `70/15/15`, random seed = `42`.  \n",
        "\n",
        "**Purpose:** Produces a clean, balanced, and reproducible **verses dataset**â€”standardised in sampling rate and qualityâ€”ready for feature extraction and deep learning models in Quranic recitation recognition.  \n"
      ],
      "metadata": {
        "id": "yth5-WuiXQnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q tensorflow\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import time\n",
        "import math\n",
        "import csv\n",
        "import random\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "tVgNSi7dcoYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRvqBPVlfOHB"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "!ffmpeg -version >/dev/null 2>&1 || sudo apt-get -y install ffmpeg\n",
        "!pip -q install requests\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/QariAI/verses_data\"\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n",
        "\n",
        "SURAH_AYAH_COUNTS = {\n",
        "    \"001\": 7,\n",
        "    \"112\": 4,\n",
        "    \"113\": 5,\n",
        "    \"114\": 6,\n",
        "}\n",
        "\n",
        "BASE_URL = \"http://www.everyayah.com/data\"\n",
        "TIMEOUT  = 60\n",
        "SESSION  = requests.Session()\n",
        "SESSION.headers.update({\"User-Agent\": \"ColabDownloader/1.0\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikWWnm_hfU0f"
      },
      "outputs": [],
      "source": [
        "ALL_RECITERS = [\n",
        "    \"AbdulSamad_64kbps_QuranExplorer.Com\",\n",
        "    \"Abdul_Basit_Mujawwad_128kbps\",\n",
        "    \"Abdul_Basit_Murattal_192kbps\",\n",
        "    \"Abdul_Basit_Murattal_64kbps\",\n",
        "    \"Abdullaah_3awwaad_Al-Juhaynee_128kbps\",\n",
        "    \"Abdullah_Basfar_192kbps\",\n",
        "    \"Abdullah_Basfar_32kbps\",\n",
        "    \"Abdullah_Basfar_64kbps\",\n",
        "    \"Abdullah_Matroud_128kbps\",\n",
        "    \"Abdurrahmaan_As-Sudais_192kbps\",\n",
        "    \"Abdurrahmaan_As-Sudais_64kbps\",\n",
        "    \"Abu Bakr Ash-Shaatree_128kbps\",\n",
        "    \"Abu_Bakr_Ash-Shaatree_128kbps\",\n",
        "    \"Abu_Bakr_Ash-Shaatree_64kbps\",\n",
        "    \"Ahmed_Neana_128kbps\",\n",
        "    \"Ahmed_ibn_Ali_al-Ajamy_128kbps_ketaballah.net\",\n",
        "    \"Ahmed_ibn_Ali_al-Ajamy_64kbps_QuranExplorer.Com\",\n",
        "    \"Akram_AlAlaqimy_128kbps\",\n",
        "    \"Alafasy_128kbps\",\n",
        "    \"Alafasy_64kbps\",\n",
        "    \"Ali_Hajjaj_AlSuesy_128kbps\",\n",
        "    \"Ali_Jaber_64kbps\",\n",
        "    \"Ayman_Sowaid_64kbps\",\n",
        "    \"English\",  # skip\n",
        "    \"Fares_Abbad_64kbps\",\n",
        "    \"Ghamadi_40kbps\",\n",
        "    \"Hani_Rifai_192kbps\",\n",
        "    \"Hani_Rifai_64kbps\",\n",
        "    \"Hudhaify_128kbps\",\n",
        "    \"Hudhaify_32kbps\",\n",
        "    \"Hudhaify_64kbps\",\n",
        "    \"Husary_128kbps\",\n",
        "    \"Husary_128kbps_Mujawwad\",\n",
        "    \"Husary_64kbps\",\n",
        "    \"Husary_Muallim_128kbps\",\n",
        "    \"Husary_Mujawwad_64kbps\",\n",
        "    \"Ibrahim_Akhdar_32kbps\",\n",
        "    \"Ibrahim_Akhdar_64kbps\",\n",
        "    \"Karim_Mansoori_40kbps\",\n",
        "    \"Khaalid_Abdullaah_al-Qahtaanee_192kbps\",\n",
        "    \"MaherAlMuaiqly128kbps\",\n",
        "    \"Maher_AlMuaiqly_64kbps\",\n",
        "    \"Menshawi_16kbps\",\n",
        "    \"Menshawi_32kbps\",\n",
        "    \"Minshawy_Mujawwad_192kbps\",\n",
        "    \"Minshawy_Mujawwad_64kbps\",\n",
        "    \"Minshawy_Murattal_128kbps\",\n",
        "    \"Minshawy_Teacher_128kbps\",\n",
        "    \"Mohammad_al_Tablaway_128kbps\",\n",
        "    \"Mohammad_al_Tablaway_64kbps\",\n",
        "    \"Muhammad_AbdulKareem_128kbps\",\n",
        "    \"Muhammad_Ayyoub_128kbps\",\n",
        "    \"Muhammad_Ayyoub_32kbps\",\n",
        "    \"Muhammad_Ayyoub_64kbps\",\n",
        "    \"Muhammad_Jibreel_128kbps\",\n",
        "    \"Muhammad_Jibreel_64kbps\",\n",
        "    \"Muhsin_Al_Qasim_192kbps\",\n",
        "    \"MultiLanguage\",  # skip\n",
        "    \"Mustafa_Ismail_48kbps\",\n",
        "    \"Nabil_Rifa3i_48kbps\",\n",
        "    \"Nasser_Alqatami_128kbps\",\n",
        "    \"Parhizgar_48kbps\",\n",
        "    \"QuranText\",       # skip\n",
        "    \"QuranText_jpg\",   # skip\n",
        "    \"Sahl_Yassin_128kbps\",\n",
        "    \"Salaah_AbdulRahman_Bukhatir_128kbps\",\n",
        "    \"Salah_Al_Budair_128kbps\",\n",
        "    \"Saood bin Ibraaheem Ash-Shuraym_128kbps\",\n",
        "    \"Saood_ash-Shuraym_128kbps\",\n",
        "    \"Saood_ash-Shuraym_64kbps\",\n",
        "    \"XML\",             # skip\n",
        "    \"Yaser_Salamah_128kbps\",\n",
        "    \"Yasser_Ad-Dussary_128kbps\",\n",
        "    \"ahmed_ibn_ali_al_ajamy_128kbps\",\n",
        "    \"aziz_alili_128kbps\",\n",
        "    \"images_png\",      # skip\n",
        "    \"khalefa_al_tunaiji_64kbps\",\n",
        "    \"mahmoud_ali_al_banna_32kbps\",\n",
        "]\n",
        "\n",
        "SKIP_NAMES = {\"English\",\"MultiLanguage\",\"QuranText\",\"QuranText_jpg\",\"XML\",\"images_png\"}\n",
        "\n",
        "KNOWN_ALIASES = {\n",
        "    \"Abu Bakr Ash-Shaatree_128kbps\": [\"Abu_Bakr_Ash-Shaatree_128kbps\"],\n",
        "    \"MaherAlMuaiqly128kbps\": [\"Maher_AlMuaiqly_64kbps\",\"MaherAlMuaiqly128kbps\"],\n",
        "    \"Husary_64kbps\": [\"Husary_64kbps\", \"Husary_Mujawwad_64kbps\"],\n",
        "    \"Husary_128kbps_Mujawwad\": [\"Husary_128kbps_Mujawwad\",\"Husary_128kbps\"],\n",
        "}\n",
        "\n",
        "def alias_candidates(name: str):\n",
        "    cands = set()\n",
        "    cands.add(name)\n",
        "    cands.add(name.replace(\" \", \"_\"))\n",
        "    cands.add(name.replace(\"_\", \" \"))\n",
        "    cands.add(name.replace(\"â€“\",\"-\").replace(\"â€”\",\"-\"))\n",
        "    if name in KNOWN_ALIASES:\n",
        "        for a in KNOWN_ALIASES[name]:\n",
        "            cands.add(a)\n",
        "            cands.add(a.replace(\" \", \"_\"))\n",
        "            cands.add(a.replace(\"_\", \" \"))\n",
        "    return list(dict.fromkeys([c for c in cands if len(c.strip())>0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOmEnsRXfXxA"
      },
      "outputs": [],
      "source": [
        "def try_fetch(reciter_alias: str, surah3: str, ayah3: str, out_mp3: Path) -> bool:\n",
        "    url = f\"{BASE_URL}/{reciter_alias}/{surah3}{ayah3}.mp3\"\n",
        "    try:\n",
        "        with SESSION.get(url, stream=True, timeout=TIMEOUT) as r:\n",
        "            if r.status_code == 200:\n",
        "                with open(out_mp3, \"wb\") as f:\n",
        "                    for chunk in r.iter_content(8192):\n",
        "                        if chunk:\n",
        "                            f.write(chunk)\n",
        "                return True\n",
        "    except requests.RequestException:\n",
        "        pass\n",
        "    return False\n",
        "\n",
        "def download_one_set(reciter_key: str, surah3: str, ayah_count: int):\n",
        "    out_dir = Path(BASE_DIR)/reciter_key/surah3/\"ayahs\"\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    ok, missing = 0, []\n",
        "    aliases = alias_candidates(reciter_key)\n",
        "    for a in range(1, ayah_count+1):\n",
        "        ayah3 = f\"{a:03d}\"\n",
        "        out_mp3 = out_dir / f\"{surah3}{ayah3}.mp3\"\n",
        "        if out_mp3.exists():\n",
        "            ok += 1\n",
        "            continue\n",
        "        got = False\n",
        "        for alias in aliases:\n",
        "            if try_fetch(alias, surah3, ayah3, out_mp3):\n",
        "                got = True\n",
        "                break\n",
        "        if got:\n",
        "            ok += 1\n",
        "        else:\n",
        "            missing.append(ayah3)\n",
        "        time.sleep(0.12)\n",
        "    keep = (ok / ayah_count) >= 0.8\n",
        "    return ok, missing, keep, out_dir\n",
        "\n",
        "manifest = []\n",
        "for rec in ALL_RECITERS:\n",
        "    if rec in SKIP_NAMES:\n",
        "        continue\n",
        "    for surah3, n_ayah in SURAH_AYAH_COUNTS.items():\n",
        "        ok, missing, keep, path = download_one_set(rec, surah3, n_ayah)\n",
        "        manifest.append((rec, surah3, ok, n_ayah, keep, str(path)))\n",
        "        print(f\"{rec} {surah3}: {ok}/{n_ayah} | keep={keep} | missing={missing}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygJg5vu9fZcJ"
      },
      "outputs": [],
      "source": [
        "def mp3_to_wav16k(mp3_path: Path) -> Path:\n",
        "    wav_path = mp3_path.with_suffix(\"\").as_posix() + \"_16k.wav\"\n",
        "    wav_path = Path(wav_path)\n",
        "    if wav_path.exists():\n",
        "        return wav_path\n",
        "    cmd = [\"ffmpeg\", \"-y\", \"-i\", str(mp3_path), \"-ac\", \"1\", \"-ar\", \"16000\", \"-sample_fmt\", \"s16\", str(wav_path)]\n",
        "    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n",
        "    return wav_path\n",
        "\n",
        "mp3s = glob.glob(os.path.join(BASE_DIR, \"*\", \"*\", \"ayahs\", \"*.mp3\"))\n",
        "print(\"MP3 found:\", len(mp3s))\n",
        "ok = fail = 0\n",
        "for i, p in enumerate(mp3s, 1):\n",
        "    try:\n",
        "        mp3_to_wav16k(Path(p)); ok += 1\n",
        "    except Exception as e:\n",
        "        print(\"Fail:\", p, e, file=sys.stderr); fail += 1\n",
        "    if i % 500 == 0:\n",
        "        print(f\"{i}/{len(mp3s)} converted...\")\n",
        "print(\"Converted OK:\", ok, \"Failed:\", fail)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qovGIeYyfik4"
      },
      "outputs": [],
      "source": [
        "def build_index(base_dir: str):\n",
        "    rows = []\n",
        "    wavs = glob.glob(os.path.join(base_dir, \"*\", \"*\", \"ayahs\", \"*_16k.wav\"))\n",
        "    pat = re.compile(rf\"^{re.escape(base_dir)}/([^/]+)/(\\d{{3}})/ayahs/(\\d{{6}})_16k\\.wav$\")\n",
        "    for w in wavs:\n",
        "        m = pat.match(w)\n",
        "        if not m:\n",
        "            continue\n",
        "        reciter, surah3, ayah6 = m.groups()\n",
        "        surah = int(surah3)\n",
        "        ayah  = int(ayah6[-3:])\n",
        "        ayah_id = int(ayah6)\n",
        "        rows.append({\"reciter\": reciter, \"surah\": surah, \"ayah\": ayah, \"ayah_id\": ayah_id, \"wav_path\": w})\n",
        "    return pd.DataFrame(rows).sort_values([\"surah\",\"ayah\",\"reciter\"]).reset_index(drop=True)\n",
        "\n",
        "df = build_index(BASE_DIR)\n",
        "csv_path = os.path.join(BASE_DIR, \"verses_index.csv\")\n",
        "df.to_csv(csv_path, index=False)\n",
        "print(\"Wrote:\", csv_path)\n",
        "print(\"Stats -> rows:\", len(df), \"| reciters:\", df.reciter.nunique(), \"| ayahs:\", df.ayah_id.nunique())\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze3WuiFuhV3t"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = \"/content/drive/MyDrive/QariAI/verses_data\"\n",
        "\n",
        "mp3s = glob.glob(os.path.join(BASE_DIR, \"*\", \"*\", \"ayahs\", \"*.mp3\"))\n",
        "wavs = glob.glob(os.path.join(BASE_DIR, \"*\", \"*\", \"ayahs\", \"*_16k.wav\"))\n",
        "\n",
        "print(\"ðŸ“¦ Download summary\")\n",
        "print(\"Total reciter folders:\", len([d for d in os.listdir(BASE_DIR) if os.path.isdir(os.path.join(BASE_DIR,d))]))\n",
        "print(\"Total MP3 files found :\", len(mp3s))\n",
        "print(\"Total 16k WAVs found  :\", len(wavs))\n",
        "\n",
        "sample = wavs[:10] if wavs else mp3s[:10]\n",
        "df = pd.DataFrame(sample, columns=[\"example_paths\"])\n",
        "print(\"\\nðŸ”Ž First few files:\")\n",
        "print(df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNK3zg9bjzWw"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = \"/content/drive/MyDrive/QariAI/verses_data\"\n",
        "SURAH_AYAH_COUNTS = {\"001\":7, \"112\":4, \"113\":5, \"114\":6}\n",
        "\n",
        "wavs = glob.glob(os.path.join(BASE_DIR, \"*\", \"*\", \"ayahs\", \"*_16k.wav\"))\n",
        "\n",
        "def parse(path):\n",
        "    m = re.search(r\"/([^/]+)/(\\d{3})/ayahs/(\\d{6})_16k\\.wav$\", path)\n",
        "    if not m: return None\n",
        "    reciter, surah3, ayah6 = m.groups()\n",
        "    return reciter, surah3, ayah6[-3:], path\n",
        "\n",
        "rows = [parse(p) for p in wavs]\n",
        "rows = [r for r in rows if r is not None]\n",
        "df = pd.DataFrame(rows, columns=[\"reciter\",\"surah\",\"ayah\",\"path\"])\n",
        "\n",
        "pivot = df.groupby([\"reciter\",\"surah\"]).size().unstack(fill_value=0)\n",
        "for s in SURAH_AYAH_COUNTS.keys():\n",
        "    if s not in pivot.columns: pivot[s] = 0\n",
        "pivot = pivot[sorted(SURAH_AYAH_COUNTS.keys())]\n",
        "\n",
        "pivot[\"total\"] = pivot.sum(axis=1)\n",
        "pivot[\"expected\"] = sum(SURAH_AYAH_COUNTS.values())\n",
        "pivot[\"pct\"] = (pivot[\"total\"] / pivot[\"expected\"]).round(3)\n",
        "\n",
        "print(\"Perâ€‘reciter counts (first 15 rows):\")\n",
        "display(pivot.head(15))\n",
        "\n",
        "missing_tbl = pivot[pivot[\"pct\"] < 1.0].sort_values(\"pct\")\n",
        "print(f\"\\nReciters with missing files: {len(missing_tbl)}\")\n",
        "display(missing_tbl.head(20))\n",
        "\n",
        "def missing_for_reciter(rec):\n",
        "    have = set(df[(df.reciter==rec)][[\"surah\",\"ayah\"]].apply(tuple, axis=1))\n",
        "    expected = {(s, f\"{i:03d}\") for s,n in SURAH_AYAH_COUNTS.items() for i in range(1, n+1)}\n",
        "    miss = sorted(expected - have)\n",
        "    return miss\n",
        "\n",
        "if len(missing_tbl):\n",
        "    rec0 = missing_tbl.index[0]\n",
        "    print(f\"\\nExample missing items for: {rec0}\")\n",
        "    print(missing_for_reciter(rec0)[:20])\n",
        "\n",
        "print(\"\\nGlobal totals:\")\n",
        "print(\"Found wavs:\", len(df))\n",
        "print(\"Unique reciters:\", df['reciter'].nunique())\n",
        "print(\"Expected per reciter:\", sum(SURAH_AYAH_COUNTS.values()))\n",
        "print(\"Max possible files:\", df['reciter'].nunique() * sum(SURAH_AYAH_COUNTS.values()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRyfTeWXkhWU"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = \"/content/drive/MyDrive/QariAI/verses_data\"\n",
        "SURAH_AYAH_COUNTS = {\"001\":7, \"112\":4, \"113\":5, \"114\":6}\n",
        "EXPECTED_PER_RECITER = sum(SURAH_AYAH_COUNTS.values())\n",
        "\n",
        "assert os.path.isdir(BASE_DIR), f\"Base not found: {BASE_DIR}\"\n",
        "\n",
        "wavs = glob.glob(os.path.join(BASE_DIR, \"*\", \"*\", \"ayahs\", \"*_16k.wav\"))\n",
        "print(\"Found WAVs:\", len(wavs))\n",
        "\n",
        "def parse_meta(path: str):\n",
        "    m = re.search(r\"/([^/]+)/(\\d{3})/ayahs/(\\d{6})_16k\\.wav$\", path)\n",
        "    if not m:\n",
        "        return None\n",
        "    reciter, surah3, ayah6 = m.groups()\n",
        "    return {\n",
        "        \"reciter\": reciter,\n",
        "        \"surah\": int(surah3),\n",
        "        \"ayah\": int(ayah6[-3:]),\n",
        "        \"ayah_id\": int(ayah6),\n",
        "        \"wav_path\": path\n",
        "    }\n",
        "\n",
        "rows = [parse_meta(p) for p in wavs]\n",
        "rows = [r for r in rows if r is not None]\n",
        "index_df = pd.DataFrame(rows).sort_values([\"surah\",\"ayah\",\"reciter\"]).reset_index(drop=True)\n",
        "\n",
        "print(\"Index stats -> rows:\", len(index_df),\n",
        "      \"| reciters:\", index_df.reciter.nunique(),\n",
        "      \"| ayahs:\", index_df.ayah_id.nunique())\n",
        "\n",
        "pivot = index_df.groupby([\"reciter\",\"surah\"]).size().unstack(fill_value=0)\n",
        "for s in SURAH_AYAH_COUNTS:\n",
        "    if int(s) not in pivot.columns:\n",
        "        pivot[int(s)] = 0\n",
        "pivot = pivot[sorted(pivot.columns)]\n",
        "\n",
        "pivot[\"total\"] = pivot.sum(axis=1)\n",
        "pivot[\"expected\"] = EXPECTED_PER_RECITER\n",
        "pivot[\"pct\"] = (pivot[\"total\"] / pivot[\"expected\"]).round(3)\n",
        "\n",
        "print(\"\\nPerâ€‘reciter coverage (first 12 rows):\")\n",
        "display(pivot.head(12))\n",
        "\n",
        "missing_tbl = pivot[pivot[\"pct\"] < 1.0].sort_values(\"pct\")\n",
        "print(f\"\\nReciters with any missing ayahs: {len(missing_tbl)}\")\n",
        "display(missing_tbl.head(10))\n",
        "\n",
        "def parse_bitrate(name: str):\n",
        "    m = re.search(r\"(\\d+)\\s*kbps\", name, flags=re.IGNORECASE)\n",
        "    return int(m.group(1)) if m else None\n",
        "\n",
        "bitrate_map = {r: parse_bitrate(r) for r in index_df.reciter.unique()}\n",
        "bitrate_series = pd.Series(bitrate_map, name=\"bitrate\").sort_index()\n",
        "\n",
        "qual = pd.DataFrame({\n",
        "    \"total_files\": index_df.groupby(\"reciter\").size(),\n",
        "    \"pct_complete\": pivot[\"pct\"],\n",
        "    \"bitrate\": bitrate_series\n",
        "}).sort_values([\"pct_complete\",\"bitrate\",\"total_files\"], ascending=[False, False, False])\n",
        "\n",
        "print(\"\\nQuality summary (top 15):\")\n",
        "display(qual.head(15))\n",
        "\n",
        "GOOD_RECITERS = qual[(qual[\"pct_complete\"] >= 1.0) & (qual[\"bitrate\"].fillna(999) >= 64)].index.tolist()\n",
        "print(f\"\\nSuggested GOOD_RECITERS (coverage=100% & bitrate>=64kbps): {len(GOOD_RECITERS)}\")\n",
        "print(GOOD_RECITERS[:20], \"...\" if len(GOOD_RECITERS) > 20 else \"\")\n",
        "\n",
        "good_df = index_df[index_df.reciter.isin(GOOD_RECITERS)]\n",
        "print(\"\\nIf we keep GOOD_RECITERS only -> rows:\", len(good_df),\n",
        "      \"| reciters:\", good_df.reciter.nunique())\n",
        "\n",
        "print(\"\\nSample index rows:\")\n",
        "display(index_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhYSIR6SklBm"
      },
      "outputs": [],
      "source": [
        "assert 'index_df' in globals() and 'GOOD_RECITERS' in globals(), \"Run Cell 1 first.\"\n",
        "\n",
        "USE_ONLY_GOOD_RECITERS   = True\n",
        "DROP_LOW_BITRATE_TAGS    = True\n",
        "REQUIRE_FULL_COVERAGE    = True\n",
        "OUT_CSV                  = os.path.join(BASE_DIR, \"verses_index.csv\")\n",
        "\n",
        "def parse_bitrate(name: str):\n",
        "    m = re.search(r\"(\\d+)\\s*kbps\", name, flags=re.IGNORECASE)\n",
        "    return int(m.group(1)) if m else None\n",
        "\n",
        "df = index_df.copy()\n",
        "\n",
        "if USE_ONLY_GOOD_RECITERS:\n",
        "    df = df[df.reciter.isin(GOOD_RECITERS)].copy()\n",
        "\n",
        "if DROP_LOW_BITRATE_TAGS:\n",
        "    df[\"bitrate\"] = df.reciter.apply(parse_bitrate)\n",
        "    df = df[(df[\"bitrate\"].isna()) | (df[\"bitrate\"] >= 64)].copy()\n",
        "    df = df.drop(columns=[\"bitrate\"])\n",
        "\n",
        "if REQUIRE_FULL_COVERAGE:\n",
        "    counts = df.groupby(\"reciter\").size()\n",
        "    full_reciters = counts[counts == counts.max()].index\n",
        "    df = df[df.reciter.isin(full_reciters)].copy()\n",
        "\n",
        "df = df.sort_values([\"surah\",\"ayah\",\"reciter\"]).reset_index(drop=True)\n",
        "\n",
        "df.to_csv(OUT_CSV, index=False)\n",
        "\n",
        "print(\"âœ… Wrote:\", OUT_CSV)\n",
        "print(\"Rows:\", len(df), \"| Reciters:\", df.reciter.nunique(), \"| Unique ayahs:\", df.ayah_id.nunique())\n",
        "print(\"\\nPerâ€‘reciter totals (first 12):\")\n",
        "display(df.groupby(\"reciter\").size().sort_values(ascending=False).head(12))\n",
        "\n",
        "print(\"\\nSample rows:\")\n",
        "display(df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWTs31Oqk6LZ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(OUT_CSV)\n",
        "\n",
        "train_df, tmp_df = train_test_split(\n",
        "    df, test_size=0.30, random_state=42, stratify=df[\"ayah_id\"]\n",
        ")\n",
        "val_df, test_df = train_test_split(\n",
        "    tmp_df, test_size=0.50, random_state=42, stratify=tmp_df[\"ayah_id\"]\n",
        ")\n",
        "\n",
        "print(\"Rows -> train:\", len(train_df), \"| val:\", len(val_df), \"| test:\", len(test_df))\n",
        "print(\"Unique ayahs in train:\", train_df.ayah_id.nunique())\n",
        "\n",
        "print(\"\\nReciters per split (counts):\")\n",
        "print(\"Train:\", train_df.reciter.nunique(),\n",
        "      \"Val:\", val_df.reciter.nunique(),\n",
        "      \"Test:\", test_df.reciter.nunique())\n",
        "\n",
        "print(\"\\nExample rows (train):\")\n",
        "display(train_df.head(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data prep & TF pipeline for the Arabic **verses** model\n",
        "\n",
        "This block takes the curated *verses* index (train/val/test DataFrames), converts raw 16 kHz WAVs into variable-length **log-mel spectrogram** tensors, builds efficient `tf.data` pipelines with on-the-fly augmentation, and trains a **BiLSTM + Attention** classifier over ayah IDs.\n",
        "\n",
        "- **Assumptions & inputs:** Expects prebuilt `train_df`, `val_df`, `test_df` with columns `wav_path` and `ayah_id` (from your earlier acquisition/curation step).\n",
        "\n",
        "- **Label mapping:**  \n",
        "  - `label_space = sorted(train_df.ayah_id.unique())`.  \n",
        "  - `tf.lookup.StaticHashTable` maps integer `ayah_id` â†’ contiguous class indices (`0â€¦NUM_CLASSES-1`).\n",
        "\n",
        "- **Audio â†’ log-mel features:**  \n",
        "  - **I/O:** Reads mono WAV at **16 kHz**; asserts sample rate.  \n",
        "  - **Duration control:** Pads/trims to **â‰¤ 16 s** (`MAX_SECONDS=16`). During training, applies **random time crop** to a target length uniformly sampled in **[6 s, 12 s]** (data augmentation).  \n",
        "  - **STFT/Mel:** `WIN=25 ms`, `HOP=10 ms`, `FFT=1024`, **64 mel bins** over **0â€“7.6 kHz**.  \n",
        "  - **Log & norm:** `log(mel+1e-6)` then per-example standardization (z-score).  \n",
        "  - **Shapes:** Time dimension varies by clip/augmentation; feature tensors are **(time, 64)**.\n",
        "\n",
        "- **tf.data pipelines:**  \n",
        "  - `make_ds(df, batch=16, shuffle, training)` â†’  \n",
        "    map(`load_and_preprocess`) â†’ **padded_batch** to `([None, 64], [])` â†’ `prefetch(AUTOTUNE)`.  \n",
        "  - Datasets: `ds_train` (shuffled + augmented), `ds_val`, `ds_test`.  \n",
        "  - Prints one batch to confirm shapes (e.g., `(batch, time_pad, 64)` and labels `(batch,)`).\n",
        "\n",
        "- **Model architecture (BiLSTM + Attention):**  \n",
        "  - **Input:** `(None, 64)` log-mel sequence with `Masking`.  \n",
        "  - **Encoder:** 2Ã— **Bidirectional LSTM(256)** with `return_sequences=True`, `dropout=0.25`.  \n",
        "  - **Attention pooling:** Custom `AttentionPool1D` learns weights over time and reduces to a single utterance embedding.  \n",
        "  - **Classifier head:** Dense(256, ReLU, **L2=1e-5**) â†’ Dropout(0.3) â†’ Dense(128, ReLU, **L2=1e-5**) â†’ Dropout(0.3) â†’ Dense(**NUM_CLASSES**, softmax).\n",
        "\n",
        "- **Compile & metrics:**  \n",
        "  - Optimizer: **AdamW(lr=1e-3, weight_decay=1e-4)** with fallback to Adam.  \n",
        "  - Loss: **sparse_categorical_crossentropy**.  \n",
        "  - Metrics: `accuracy` and **SparseTopKCategoricalAccuracy(k=5)** (`top5`).\n",
        "\n",
        "- **Training & checkpointing:**  \n",
        "  - **EPOCHS=40** with callbacks:  \n",
        "    - `ModelCheckpoint(..., monitor=\"val_accuracy\", save_best_only=True)` â†’ saves to `best_verses_bilstm_attn.keras`.  \n",
        "    - `EarlyStopping(monitor=\"val_accuracy\", patience=7, restore_best_weights=True)`.  \n",
        "    - `ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5)`.  \n",
        "  - Trains on `ds_train`, validates on `ds_val`.\n",
        "\n",
        "- **Evaluation:**  \n",
        "  - Reloads the best checkpoint (registering `AttentionPool1D`) and reports a metrics dict on **`ds_test`** (includes `loss`, `accuracy`, and `top5`).\n",
        "\n",
        "**Key hyperparameters:** `SR=16000`, `N_MELS=64`, `WIN=0.025 s`, `HOP=0.010 s`, `FFT=1024`, `FMIN=0`, `FMAX=7600`, `MAX_SECONDS=16`, random crop in **[6 s, 12 s]**, `BATCH=16`, `EPOCHS=40`, `L2=1e-5`, `Dropout=0.25/0.3`, `lr=1e-3`.\n",
        "\n",
        "**Purpose:** End-to-end preparation and training for **verse-level** recognition with variable-length inputsâ€”augmenting in time, pooling with attention, and reporting accuracy/top-5 on a held-out test set for robust evaluation.\n"
      ],
      "metadata": {
        "id": "ppXnz3L8YTDD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4XGbw5BlHTN"
      },
      "outputs": [],
      "source": [
        "SR = 16000\n",
        "N_MELS = 64\n",
        "WIN = int(0.025 * SR)\n",
        "HOP = int(0.010 * SR)\n",
        "FFT = 1024\n",
        "FMIN, FMAX = 0.0, 7600.0\n",
        "\n",
        "MAX_SECONDS = 16\n",
        "MAX_SAMPLES = SR * MAX_SECONDS\n",
        "\n",
        "label_space = sorted(train_df.ayah_id.unique())\n",
        "NUM_CLASSES = len(label_space)\n",
        "keys = tf.constant(label_space, dtype=tf.int64)\n",
        "vals = tf.range(NUM_CLASSES, dtype=tf.int64)\n",
        "table = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(keys, vals), default_value=-1)\n",
        "\n",
        "def wav_to_logmel(audio_1d):\n",
        "    stft = tf.signal.stft(audio_1d, frame_length=WIN, frame_step=HOP,\n",
        "                          fft_length=FFT, window_fn=tf.signal.hann_window, pad_end=True)\n",
        "    mag2 = tf.abs(stft) ** 2\n",
        "    num_bins = FFT // 2 + 1\n",
        "    mel_w = tf.signal.linear_to_mel_weight_matrix(\n",
        "        num_mel_bins=N_MELS, num_spectrogram_bins=num_bins,\n",
        "        sample_rate=SR, lower_edge_hertz=FMIN, upper_edge_hertz=FMAX\n",
        "    )\n",
        "    mel = tf.tensordot(mag2, mel_w, 1)\n",
        "    mel.set_shape(mag2.shape[:-1].concatenate(mel_w.shape[-1:]))\n",
        "    logmel = tf.math.log(mel + 1e-6)\n",
        "    mean, std = tf.reduce_mean(logmel), tf.math.reduce_std(logmel)\n",
        "    return (logmel - mean) / (std + 1e-6)\n",
        "\n",
        "def random_time_crop(audio, target_len):\n",
        "    n = tf.shape(audio)[0]\n",
        "    def crop():\n",
        "        start = tf.random.uniform((), 0, n - target_len + 1, dtype=tf.int32)\n",
        "        return audio[start:start+target_len]\n",
        "    return tf.cond(n > target_len, crop, lambda: tf.pad(audio, [[0, target_len - n]]))\n",
        "\n",
        "def load_and_preprocess(path, ayah_id, training=False):\n",
        "    audio_bytes = tf.io.read_file(path)\n",
        "    audio, sr = tf.audio.decode_wav(audio_bytes, desired_channels=1)\n",
        "    audio = tf.squeeze(audio, -1)\n",
        "    tf.debugging.assert_equal(sr, tf.constant(SR, dtype=sr.dtype), \"SR must be 16k\")\n",
        "    if training:\n",
        "        target = tf.random.uniform((), minval=6*SR, maxval=12*SR, dtype=tf.int32)\n",
        "        audio = random_time_crop(audio, target)\n",
        "    audio = tf.cond(tf.shape(audio)[0] < MAX_SAMPLES,\n",
        "                    lambda: tf.pad(audio, [[0, MAX_SAMPLES - tf.shape(audio)[0]]]),\n",
        "                    lambda: audio[:MAX_SAMPLES])\n",
        "    feat = wav_to_logmel(audio)\n",
        "    y = table.lookup(tf.cast(ayah_id, tf.int64))\n",
        "    return feat, y\n",
        "\n",
        "def make_ds(frame, batch=16, shuffle=False, training=False):\n",
        "    paths = frame[\"wav_path\"].astype(str).values\n",
        "    ids   = frame[\"ayah_id\"].astype(np.int64).values\n",
        "    ds = tf.data.Dataset.from_tensor_slices((paths, ids))\n",
        "    if shuffle: ds = ds.shuffle(min(len(frame), 8000), reshuffle_each_iteration=True)\n",
        "    ds = ds.map(lambda p, i: load_and_preprocess(p, i, training=training),\n",
        "                num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.padded_batch(batch, padded_shapes=([None, N_MELS], []), drop_remainder=False)\n",
        "    return ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "BATCH = 16\n",
        "ds_train = make_ds(train_df, batch=BATCH, shuffle=True,  training=True)\n",
        "ds_val   = make_ds(val_df,   batch=BATCH, shuffle=False, training=False)\n",
        "ds_test  = make_ds(test_df,  batch=BATCH, shuffle=False, training=False)\n",
        "\n",
        "print(\"âœ… datasets ready\")\n",
        "for ds, name in [(ds_train,\"train\"),(ds_val,\"val\"),(ds_test,\"test\")]:\n",
        "    for feat, y in ds.take(1):\n",
        "        print(f\"{name} batch -> feat:\", feat.shape, \"labels:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD9fQcI-l4eJ"
      },
      "outputs": [],
      "source": [
        "class AttentionPool1D(layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.score = layers.Dense(1)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        a = self.score(x)\n",
        "        if mask is not None:\n",
        "            mask_exp = tf.cast(mask, tf.bool)[..., None]\n",
        "            neg_inf = tf.fill(tf.shape(a), tf.constant(-1e9, a.dtype))\n",
        "            a = tf.where(mask_exp, a, neg_inf)\n",
        "        w = tf.nn.softmax(a, axis=1)\n",
        "        return tf.reduce_sum(w * x, axis=1)\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return None\n",
        "\n",
        "inputs = layers.Input(shape=(None, N_MELS), name=\"logmel\")\n",
        "x = layers.Masking()(inputs)\n",
        "\n",
        "x = layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=0.25))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=0.25))(x)\n",
        "\n",
        "z = AttentionPool1D(name=\"attn_pool\")(x)\n",
        "\n",
        "z = layers.Dense(256, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(1e-5))(z)\n",
        "z = layers.Dropout(0.3)(z)\n",
        "z = layers.Dense(128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(1e-5))(z)\n",
        "z = layers.Dropout(0.3)(z)\n",
        "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(z)\n",
        "\n",
        "model = Model(inputs, outputs, name=\"Verses_BiLSTM_Attn\")\n",
        "\n",
        "try:\n",
        "    opt = tf.keras.optimizers.experimental.AdamW(learning_rate=1e-3, weight_decay=1e-4)\n",
        "except Exception:\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "loss_fn = \"sparse_categorical_crossentropy\"\n",
        "top5 = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name=\"top5\")\n",
        "\n",
        "model.compile(optimizer=opt, loss=loss_fn, metrics=[\"accuracy\", top5])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zyt2dRy3mhah"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 40\n",
        "CKPT   = os.path.join(BASE_DIR, \"best_verses_bilstm_attn.keras\")\n",
        "\n",
        "cbs = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        CKPT, monitor=\"val_accuracy\", save_best_only=True, verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\", patience=7, restore_best_weights=True, verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5, verbose=1\n",
        "    ),\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_val,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=cbs,\n",
        ")\n",
        "\n",
        "print(\"Loading best checkpoint:\", CKPT)\n",
        "best_model = tf.keras.models.load_model(CKPT, custom_objects={\"AttentionPool1D\": type(model.get_layer('attn_pool'))})\n",
        "\n",
        "print(\"Evaluating on TESTâ€¦\")\n",
        "test_metrics = best_model.evaluate(ds_test, return_dict=True)\n",
        "print(test_metrics)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
